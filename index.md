---
layout: homepage
---

## Short Bio

I am an Assistant Researcher (2024-) in the [School of Computer Science](https://cs.nju.edu.cn/main.htm) at [Nanjing University](http://www.nju.edu.cn/). I am a member of [DisLab](http://dislab.nju.edu.cn). 
Previously, I received my Ph.D. (2018-2024) from [Nanjing University](http://www.nju.edu.cn/), advised by  Prof. [Lei Xie](https://cs.nju.edu.cn/lxie/index.htm). 
I was fortunate to visit [Nanyang Technological University](https://www.ntu.edu.sg) (2022-2023), working closely with Prof. [Jun Lup](https://personal.ntu.edu.sg/junluo/. 

My research interests include machine learning and its applications in computer vision, currently focusing on continual learning, pre-trained model reuse, and multimodal large language models.

<!-- <div class="highlighted-text">
  <i class="fa-regular fa-bell"></i>&nbsp;
I am looking for highly self-motivated students. Please drop me an email with your resume and transcript if you are interested in working together with me.
</div> -->

## News
<div class="container custom-scrollbar" style="height:200px;width:103%;overflow:auto;">
  <li>[2024-09] One paper about class-incremental learning with PTM is accepted to <a href="https://link.springer.com/journal/10994" target="_blank">MLJ</a>.</li>
  <li>[2024-08] One paper about <a href="http://arxiv.org/abs/2303.07338" target="_blank">class-incremental learning with PTM</a> is accepted to <a href="https://link.springer.com/journal/11263" target="_blank">IJCV</a>.</li>
  <li>[2024-07] One survey about <a href="https://arxiv.org/abs/2302.03648" target="_blank">class-incremental learning</a> is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI</a>.</li>
  <li> [2024-06] One paper about multilingual MLLM is uploaded to <a href="https://arxiv.org/abs/2406.02539" target="_blank">arXiv</a>.</li>
  <li> [2024-05] Successfully defended my Ph.D. dissertation. </li>
  <li> [2024-05] Recognized as <a href="https://cvpr.thecvf.com/Conferences/2024/ProgramCommittee#outstanding-reviewers" target="_blank">CVPR 2024 Outstanding Reviewer</a>.</li>
  <li> [2024-05] One paper about <a href="https://openreview.net/forum?id=aksdU1KOpT" target="_blank">class-incremental learning</a> is accepted to <a href="https://icml.cc/" target="_blank">ICML 2024</a>.</li>
  <li>[2024-04] One survey about <a href="https://arxiv.org/abs/2401.16386" target="_blank">PTM-based continual learning</a> is accepted to <a href="https://ijcai24.org/" target="_blank">IJCAI 2024</a>.</li>
  <li> [2024-02] One paper about <a href="https://arxiv.org/abs/2403.12030" target="_blank">class-incremental learning</a> is accepted to <a href="http://cvpr2024.thecvf.com/" target="_blank">CVPR 2024</a>.</li>
  <li> [2023-11] Recognized as <a href="https://neurips.cc/Conferences/2023/ProgramCommittee#top-reivewers" target="_blank">NeurIPS 2023 Top Reviewer</a>.</li>
  <li>[2023-09] One paper about <a href="  https://openreview.net/forum?id=8NAxGDdf7H" target="_blank">few-shot class-incremental learning</a> is accepted to <a href="https://neurips.cc/Conferences/2023" target="_blank">NeurIPS 2023</a>.</li>
  <li>[2023-09] We have released <a href="https://github.com/sun-hailong/LAMDA-PILOT" target="_blank">PILOT toolbox</a> for class-incremental learning with pre-trained models (<a href="https://arxiv.org/abs/2309.07117" target="_blank">technical report</a>). </li>
  <li>[2023-09] One paper about <a href="http://arxiv.org/abs/2106.08112" target="_blank">contextualized meta-learning</a> is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI</a>.</li>
  <li>[2023-08] We are hosting the <a href="#tutorials"> tutorial </a> (<a href="./file/cl_tutorial.pdf" target="_blank">slides</a>) on continual learning at <a href="https://ijcai-23.org/tutorials/" target="_blank">IJCAI 2023</a>.</li>
  <li>[2023-05] One paper about class-incremental learning with VLM is uploaded to <a href="https://arxiv.org/abs/2305.19270" target="_blank">arXiv</a>.</li>
  <li>[2023-01] Two papers about class-incremental learning are accepted to <a href="https://iclr.cc/" target="_blank">ICLR 2023</a> (one <a href="https://openreview.net/forum?id=S07feAlQHgM" target="_blank">spotlight</a>).</li>
  <li>[2022-10] Our <a href="https://github.com/G-U-N/PyCIL" target="_blank">toolbox for class-incremental learning (PyCIL)</a> is accepted to <a href="https://www.sciengine.com/SCIS/home" target="_blank">SCIS</a>.</li>
  <li>[2022-08] One paper about <a href="https://ieeexplore.ieee.org/document/9864267" target="_blank">few-shot class-incremental learning</a> is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34" target="_blank">TPAMI</a>.</li>
  <li>[2022-07] One paper about <a href="https://arxiv.org/abs/2204.04662" target="_blank">class-incremental learning</a> is accepted to <a href="https://eccv2022.ecva.net/" target="_blank">ECCV 2022</a>.</li>
  <li> [2022-03] One paper about <a href="https://arxiv.org/abs/2203.06953" target="_blank">few-shot class-incremental learning</a> is accepted to <a href="http://cvpr2022.thecvf.com/" target="_blank">CVPR 2022</a>.</li>
  <li>[2021-08] One paper about <a href="https://ieeexplore.ieee.org/document/9533187" target="_blank">open-world learning</a> is accepted to <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385" target="_blank">TNNLS</a>.</li>
  <li>[2021-07] One paper about <a href="http://arxiv.org/abs/2107.12654" target="_blank">class-incremental learning</a> is accepted to <a href="https://2021.acmmm.org/" target="_blank">ACM MM 2021</a>.</li>
  <li>[2021-03] One oral paper about <a href="http://arxiv.org/abs/2103.15086" target="_blank">open-set recognition</a> is accepted to <a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR 2021</a>.</li>        
</div>


## Selected Publications 



For more details, please view the <a href="./publication.html">full publication page</a> or <a href="https://scholar.google.com/citations?user=kMNaR-YAAAAJ&hl=en" target="_blank">Google Scholar profile</a>. 







### Conference Paper
<div class="publications">
<ol class="bibliography">


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/MoirePose.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div id="memo" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Expandable Subspace Ensemble for
Pre-Trained Model-Based Class-Incremental Learning</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Hai-Long Sun, Han-Jia Ye, De-Chuan Zhan</div>
  <div class="periodical"><em>The IEEE/CVF Conference on Computer Vision and Pattern Recognition. <strong><i style="color:#1e90ff">CVPR 2024</i></strong>. </em> 
  </div>
 [<a href="https://arxiv.org/abs/2403.12030" target="_blank">Paper</a>] 
[<a href="https://github.com/sun-hailong/CVPR24-Ease">Code</a>] 
<br>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/ptm-cl-survey.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">IJCAI</abbr> 
  </div>
  <div id="ptm_cl_survey" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Continual Learning with Pre-Trained Models: A Survey</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Hai-Long Sun, Jingyi Ning, Han-Jia Ye, De-Chuan Zhan</div>
  <div class="periodical"><em> The 33rd International Joint
Conference on Artificial Intelligence. <strong><i style="color:#1e90ff">IJCAI 2024</i></strong>. </em> 
  </div>
[<a href="https://arxiv.org/abs/2401.16386" target="_blank">Paper</a>]
[<a href="https://github.com/sun-hailong/LAMDA-PILOT">Code</a>]
[<a href="https://mp.weixin.qq.com/s/dWumvQxhlItc_Lo2uv4SEg">Media</a>]
 <!-- [<a href="https://zhuanlan.zhihu.com/p/681100367">中文解读</a>] -->
  <br>
 <img src="https://img.shields.io/github/stars/sun-hailong/LAMDA-PILOT?style=flat&label=Stars&logo=github&labelColor=f6f6f6&color=9cf&logoColor=020d12"/>
  </div>
</div>
</li>




<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/3ef.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICLR</abbr>
  </div>
  <div id="beef" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">BEEF: Bi-Compatible Class-Incremental Learning via Energy-Based Expansion and Fusion </div>
  <div class="author">Fu-Yun Wang, <strong>Da-Wei Zhou</strong>, Liu Liu, Yatao Bian, Han-Jia Ye, De-Chuan Zhan, Peilin Zhao</div>
  <div class="periodical"><em>The 11th International Conference on Learning Representations. <strong><i style="color:#1e90ff">ICLR 2023</i></strong>. </em> 
  </div>
[<a href="https://openreview.net/forum?id=iP77_axu0h3" target="_blank">Paper</a>] 
[<a href="https://github.com/G-U-N/ICLR23-BEEF">Code</a>]
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/teen.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">NeurIPS</abbr>
  </div>
  <div id="teen" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Few-Shot Class-Incremental Learning via Training-Free Prototype Calibration</div>
  <div class="author">Qi-Wei Wang, <strong>Da-Wei Zhou</strong>, Yi-Kai Zhang,  De-Chuan Zhan, Han-Jia Ye</div>
  <div class="periodical"><em>The 37th Conference on Neural Information Processing Systems. <strong><i style="color:#1e90ff">NeurIPS 2023</i></strong>. </em> 
  </div>
[<a href="https://openreview.net/forum?id=8NAxGDdf7H" target="_blank">Paper</a>] 
[<a href="https://github.com/wangkiw/TEEN">Code</a>]
<br>
  </div>
</div>
</li>



<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/fact.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR</abbr>
  </div>
  <div id="fact" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Forward Compatible Few-Shot Class-Incremental Learning</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Fu-Yun Wang, Han-Jia Ye, Liang Ma, Shiliang Pu, De-Chuan Zhan</div>
  <div class="periodical"><em>IEEE Conference on Computer Vision and Pattern Recognition. <strong><i style="color:#1e90ff">CVPR 2022</i></strong>.</em>
  </div>
[<a href="https://arxiv.org/abs/2203.06953" target="_blank">Paper</a>]
[<a href="./file/CVPR22/CVPR22_project.html" target="_blank">Project Page</a>]
[<a href="https://github.com/zhoudw-zdw/CVPR22-Fact" target="_blank">Code</a>]
<br>
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/foster.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ECCV</abbr>
  </div>
  <div id="foster" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">FOSTER: Feature Boosting and Compression for Class-Incremental Learning</div>
  <div class="author">Fu-Yun Wang, <strong>Da-Wei Zhou</strong>, Han-Jia Ye, De-Chuan Zhan</div>
  <div class="periodical"><em>European Conference on Computer Vision. <strong><i style="color:#1e90ff">ECCV 2022</i></strong>.</em>
  </div>
[<a href="https://arxiv.org/abs/2204.04662" target="_blank">Paper</a>]
 [<a href="https://github.com/G-U-N/ECCV22-FOSTER">Code</a>]
 <br>
  <!-- <img src="https://img.shields.io/badge/dynamic/json?style=plastic&labelColor=f6f6f6&color=9cf&style=flat&label=Citations&logo=Google%20Scholar&query=publications%5B1%5D.citations&url=https%3A%2F%2Fcse.bth.se%2F~fer%2Fgooglescholar-api%2Fgooglescholar.php%3Fuser%3DkMNaR-YAAAAJ"> -->
  <img src="https://img.shields.io/badge/dynamic/json?labelColor=f6f6f6&color=9cf&style=flat&label=Citations&logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhoudw7%2Fzhoudw7.github.io@google-scholar-stats%2Fgs_data.json&query=$[%27publications%27][%27kMNaR-YAAAAJ:8k81kl-MbHgC%27][%27num_citations%27]">
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/proser.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">CVPR Oral</abbr>
  </div>
  <div id="proser" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Learning Placeholders for Open-Set Recognition</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Han-Jia Ye, De-Chuan Zhan</div>
  <div class="periodical"><em>IEEE Conference on Computer Vision and Pattern Recognition. <strong><i style="color:#1e90ff">CVPR 2021</i></strong>. </em> <strong><i style="color:#e74d3c">Oral Presentation</i></strong>
  </div>
[<a href="https://arxiv.org/abs/2103.15086" target="_blank">Paper</a>]
[<a href="./file/CVPR21/CVPR21_project.html" target="_blank">Project Page</a>]
[<a href="https://github.com/zhoudw-zdw/CVPR21-Proser" target="_blank">Code</a>]
<br>

 <img src="https://img.shields.io/badge/dynamic/json?labelColor=f6f6f6&color=9cf&style=flat&label=Citations&logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhoudw7%2Fzhoudw7.github.io@google-scholar-stats%2Fgs_data.json&query=$[%27publications%27][%27kMNaR-YAAAAJ:Tyk-4Ss8FVUC%27][%27num_citations%27]">
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/coil.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ACM MM</abbr>
  </div>
  <div id="coil" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Co-Transport for Class-Incremental Learning</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Han-Jia Ye, De-Chuan Zhan</div>
  <div class="periodical"><em>The 29th ACM International Conference on Multimedia.  <strong><i style="color:#1e90ff">ACM MM 2021</i></strong>.</em>
  </div>
  [<a href="http://arxiv.org/abs/2107.12654" target="_blank">Paper</a>]
  [<a href="file/MM21/MM21_project.html" target="_blank">Project Page</a>]
  [<a href="https://github.com/zhoudw-zdw/MM21-Coil" target="_blank">Code</a>]
  <br>
   <img src="https://img.shields.io/badge/dynamic/json?labelColor=f6f6f6&color=9cf&style=flat&label=Citations&logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhoudw7%2Fzhoudw7.github.io@google-scholar-stats%2Fgs_data.json&query=$[%27publications%27][%27kMNaR-YAAAAJ:WF5omc3nYNoC%27][%27num_citations%27]">
  </div>
</div>
</li>




</ol>
</div>


### Journal Article
<div class="publications">
<ol class="bibliography">

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/adam.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">IJCV</abbr> 
  </div>
  <div id="adam" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Revisiting Class-Incremental Learning with Pre-Trained Models: Generalizability and Adaptivity are All You Need</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Zi-Wen Cai, Han-Jia Ye, De-Chuan Zhan, Ziwei Liu</div>
  <div class="periodical"><em>International Journal of Computer Vision. <strong><i style="color:#1e90ff">IJCV</i></strong>.</em>
  </div>
[<a href="http://arxiv.org/abs/2303.07338" target="_blank">Paper</a>]
[<a href="https://github.com/zhoudw-zdw/RevisitingCIL">Code</a>]
[<a href="https://mp.weixin.qq.com/s/CACAaD2F1NvH4MJ1eCvpNA">Media</a>]
<br>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/cil_survey.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">TPAMI</abbr> 
  </div>
  <div id="cil_survey" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Class-Incremental Learning: A Survey</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Qi-Wei Wang, Zhi-Hong Qi, Han-Jia Ye, De-Chuan Zhan, Ziwei Liu</div>
    <div class="periodical"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence. <strong><i style="color:#1e90ff">TPAMI</i></strong>.</em>  
  </div>
[<a href="https://arxiv.org/abs/2302.03648" target="_blank">Paper</a>]
[<a href="https://github.com/zhoudw-zdw/CIL_Survey">Code</a>]
[<a href="https://mp.weixin.qq.com/s/n3MwLm8MpuXeE4o-D7H0jw">Media</a>]
 [<a href="https://zhuanlan.zhihu.com/p/605208282">中文解读</a>]
  <br>
 <img src="https://img.shields.io/badge/dynamic/json?labelColor=f6f6f6&color=9cf&style=flat&label=Citations&logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhoudw7%2Fzhoudw7.github.io@google-scholar-stats%2Fgs_data.json&query=$[%27publications%27][%27kMNaR-YAAAAJ:TQgYirikUcIC%27][%27num_citations%27]">
 <img src="https://img.shields.io/github/stars/zhoudw-zdw/CIL_survey?style=flat&label=Stars&logo=github&labelColor=f6f6f6&color=9cf&logoColor=020d12"/>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/limit.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">TPAMI</abbr>
  </div>
  <div id="limit" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Few-Shot Class-Incremental Learning by
Sampling Multi-Phase Tasks</div>
  <div class="author"><strong>Da-Wei Zhou</strong>, Han-Jia Ye, Liang Ma, Di Xie, Shiliang Pu, De-Chuan Zhan</div>
  <div class="periodical"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence. <strong><i style="color:#1e90ff">TPAMI</i></strong>.</em> <strong><i style="color:#e74d3c">ESI Highly Cited Paper</i></strong>
  </div>
 [<a href="https://arxiv.org/abs/2203.17030" target="_blank">Paper</a>]
[<a href="https://github.com/zhoudw-zdw/Limit" target="_blank">Code</a>]
<br>
 <img src="https://img.shields.io/badge/dynamic/json?labelColor=f6f6f6&color=9cf&style=flat&label=Citations&logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhoudw7%2Fzhoudw7.github.io@google-scholar-stats%2Fgs_data.json&query=$[%27publications%27][%27kMNaR-YAAAAJ:0EnyYjriUFMC%27][%27num_citations%27]">
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/leadnet.jpg" class="teaser img-fluid z-depth-1">
    <abbr class="badge">TPAMI</abbr> 
  </div>
  <div id="leadnet" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">Contextualizing Meta-Learning via Learning to Decompose</div>
  <div class="author">Han-Jia Ye, <strong>Da-Wei Zhou</strong>, Lanqing Hong, Zhenguo Li, Xiu-Shen Wei, De-Chuan Zhan</div>
  <div class="periodical"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence. <strong><i style="color:#1e90ff">TPAMI</i></strong>.</em>  
  </div>
 [<a href="https://arxiv.org/abs/2106.08112" target="_blank">Paper</a>]
 [<a href="https://github.com/zhoudw-zdw/LeadNet" target="_blank">Code</a>]
  </div>
</div>
</li>


<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="file/teaser/pycil.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">SCIS</abbr>
  </div>
  <div id="pycil" class="col-sm-9" style="position: relative;width: 100%;padding-right: 15px;padding-left: 20px;">
  <div class="title">PyCIL: A Python Toolbox for Class-Incremental Learning</div>
  <div class="author"><strong>Da-Wei Zhou*</strong>, Fu-Yun Wang*, Han-Jia Ye, De-Chuan Zhan </div>
  <div class="periodical"><em>SCIENCE CHINA Information Sciences. <strong><i style="color:#1e90ff">SCIS</i></strong>.</em>
  </div>
 [<a href="https://arxiv.org/abs/2112.12533" target="_blank">Paper</a>]
 [<a href="https://github.com/G-U-N/PyCIL">Code</a>] 
 [<a href="https://mp.weixin.qq.com/s/A472p7XGZMhAMAR2wyHZJw">Media</a>] 
 [<a href="https://mp.weixin.qq.com/s/h1qu2LpdvjeHAPLOnG478A">中文解读</a>]
 <br>
<img src="https://img.shields.io/badge/dynamic/json?labelColor=f6f6f6&color=9cf&style=flat&label=Citations&logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fzhoudw7%2Fzhoudw7.github.io@google-scholar-stats%2Fgs_data.json&query=$[%27publications%27][%27kMNaR-YAAAAJ:qxL8FJ1GzNcC%27][%27num_citations%27]">
<img src="https://img.shields.io/github/stars/G-U-N/PyCIL?style=flat&label=Stars&logo=github&labelColor=f6f6f6&color=9cf&logoColor=020d12"/>
<img src="https://img.shields.io/github/forks/G-U-N/PyCIL?style=flat&label=Forks&logo=github&labelColor=f6f6f6&color=9cf&logoColor=020d12"/>
  </div>
</div>
</li>


</ol>
</div>


<!-- ## Contact

- **Office**: Room A202, Yifu Building, Nanjing University Xianlin Campus. 
- **Email**: zhoudw (at) lamda.nju.edu.cn **OR** zhoudw  (at) nju.edu.cn -->
